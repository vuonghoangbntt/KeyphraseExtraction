21-11-04 17:35:25, INFO: 
***************** SEMEVAL2017_RNN **************
21-11-04 17:35:25, INFO: batch_size: 4
21-11-04 17:35:25, INFO: data_name: SemEval2017
21-11-04 17:35:25, INFO: decode_emb_dim: 128
21-11-04 17:35:25, INFO: file_name: SemEval2017_RNN
21-11-04 17:35:25, INFO: glove_size: 300
21-11-04 17:35:25, INFO: hidden_size: 256
21-11-04 17:35:25, INFO: loss_weight: 3.,2.,1
21-11-04 17:35:25, INFO: lr: 0.01
21-11-04 17:35:25, INFO: num_epoch: 10
21-11-04 17:35:25, INFO: num_epoch_save: 2
21-11-04 17:35:25, INFO: num_layers: 2
21-11-04 17:35:25, INFO: test_size: 0.2
21-11-04 17:35:25, INFO: use_pretrain: True
21-11-04 17:35:25, INFO: --------------------------------
21-11-04 17:35:25, INFO: Seq2Seq(
  (encoder): Encoder(
    (embedding): Embedding(400004, 300)
    (rnn): LSTM(300, 256, num_layers=2, dropout=0.5)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Decoder(
    (embedding): Embedding(3, 128)
    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)
    (fc_out): Linear(in_features=256, out_features=3, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
21-11-04 17:35:25, INFO: --------------------------------
21-11-04 17:36:42, INFO: ---------------------------------------Epoch 1---------------------------------------
21-11-04 17:36:42, INFO: Train: loss 0.11648337959032978, precision_score 0.361480477981222, recall_score 0.36061996857180517, f1_score 0.34604156305360084
21-11-04 17:36:42, INFO: Test: loss 0.1502655130444151, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:37:55, INFO: ---------------------------------------Epoch 2---------------------------------------
21-11-04 17:37:55, INFO: Train: loss 0.10775213034322419, precision_score 0.40186709271977267, recall_score 0.3930810100054294, f1_score 0.38225868116349626
21-11-04 17:37:55, INFO: Test: loss 0.15327300778543107, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:39:15, INFO: ---------------------------------------Epoch 3---------------------------------------
21-11-04 17:39:15, INFO: Train: loss 0.1079344683643525, precision_score 0.3619219026227772, recall_score 0.35272367728935805, f1_score 0.3439690253053668
21-11-04 17:39:15, INFO: Test: loss 0.16201342326222043, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:40:30, INFO: ---------------------------------------Epoch 4---------------------------------------
21-11-04 17:40:30, INFO: Train: loss 0.11111056207097726, precision_score 0.3905560485763531, recall_score 0.3826042209233922, f1_score 0.36989795437586387
21-11-04 17:40:30, INFO: Test: loss 0.16481322260818096, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:41:47, INFO: ---------------------------------------Epoch 5---------------------------------------
21-11-04 17:41:47, INFO: Train: loss 0.10700825703930734, precision_score 0.37050610516213894, recall_score 0.36456375120794754, f1_score 0.3535274395637233
21-11-04 17:41:47, INFO: Test: loss 0.1575135432108484, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:42:58, INFO: ---------------------------------------Epoch 6---------------------------------------
21-11-04 17:42:58, INFO: Train: loss 0.10816621061811592, precision_score 0.40063169804406723, recall_score 0.380541126951534, f1_score 0.3773743818274549
21-11-04 17:42:58, INFO: Test: loss 0.16089496347639295, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:44:18, INFO: ---------------------------------------Epoch 7---------------------------------------
21-11-04 17:44:18, INFO: Train: loss 0.10591967002994518, precision_score 0.3732242833681696, recall_score 0.36243706628443756, f1_score 0.3539574965392913
21-11-04 17:44:18, INFO: Test: loss 0.14270272580060092, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:45:29, INFO: ---------------------------------------Epoch 8---------------------------------------
21-11-04 17:45:29, INFO: Train: loss 0.10636704872707425, precision_score 0.3861136322192376, recall_score 0.38526569694240026, f1_score 0.370564602851644
21-11-04 17:45:29, INFO: Test: loss 0.15276457384379225, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:46:45, INFO: ---------------------------------------Epoch 9---------------------------------------
21-11-04 17:46:45, INFO: Train: loss 0.10745367120365201, precision_score 0.3913344517729162, recall_score 0.3836012489942506, f1_score 0.37157910663508886
21-11-04 17:46:45, INFO: Test: loss 0.14626938766903347, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:47:58, INFO: ---------------------------------------Epoch 10---------------------------------------
21-11-04 17:47:58, INFO: Train: loss 0.10832606324084519, precision_score 0.3594362031309502, recall_score 0.3524974221946271, f1_score 0.34138621251486345
21-11-04 17:47:58, INFO: Test: loss 0.16580499211947122, precision_score 0.3205181062323919, recall_score 0.3435846560846561, f1_score 0.31710758377425047
21-11-04 17:48:01, INFO: --------------------------------------------------------------------------------------
21-11-04 17:48:01, INFO:                                        Result                                         
21-11-04 17:48:01, INFO: --------------------------------------------------------------------------------------
21-11-04 17:48:36, INFO: Train:
21-11-04 17:48:36, INFO: 
              precision    recall  f1-score   support

           B       0.09      0.26      0.14       142
           I       0.17      0.11      0.13       101
           O       0.86      0.72      0.78      1329

    accuracy                           0.64      1572
   macro avg       0.37      0.36      0.35      1572
weighted avg       0.75      0.64      0.68      1572

21-11-04 17:48:36, INFO: Test: 
21-11-04 17:48:36, INFO: 
              precision    recall  f1-score   support

           B       0.10      0.28      0.15        36
           I       0.00      0.00      0.00        21
           O       0.86      0.75      0.80       336

    accuracy                           0.67       393
   macro avg       0.32      0.34      0.32       393
weighted avg       0.74      0.67      0.70       393


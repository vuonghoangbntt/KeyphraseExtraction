21-11-04 16:45:10, INFO: 
***************** INSPEC_RNN **************
21-11-04 16:45:10, INFO: batch_size: 4
21-11-04 16:45:10, INFO: data_name: Inspec
21-11-04 16:45:10, INFO: decode_emb_dim: 128
21-11-04 16:45:10, INFO: file_name: Inspec_RNN
21-11-04 16:45:10, INFO: glove_size: 300
21-11-04 16:45:10, INFO: hidden_size: 256
21-11-04 16:45:10, INFO: lr: 0.01
21-11-04 16:45:10, INFO: num_epoch: 10
21-11-04 16:45:10, INFO: num_epoch_save: 2
21-11-04 16:45:10, INFO: num_layers: 2
21-11-04 16:45:10, INFO: test_size: 0.2
21-11-04 16:45:10, INFO: use_pretrain: True
21-11-04 16:45:10, INFO: --------------------------------
21-11-04 16:45:10, INFO: Seq2Seq(
  (encoder): Encoder(
    (embedding): Embedding(400004, 300)
    (rnn): LSTM(300, 256, num_layers=2, dropout=0.5)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Decoder(
    (embedding): Embedding(3, 128)
    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)
    (fc_out): Linear(in_features=256, out_features=3, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
21-11-04 16:45:10, INFO: --------------------------------
21-11-04 16:49:26, INFO: ---------------------------------------Epoch 1---------------------------------------
21-11-04 16:49:26, INFO: Train: loss 0.05415189856197685, precision_score 0.382780946354414, recall_score 0.3673159088433045, f1_score 0.35904273215406085
21-11-04 16:49:26, INFO: Test: loss 0.0812429229915142, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 16:53:29, INFO: ---------------------------------------Epoch 2---------------------------------------
21-11-04 16:53:29, INFO: Train: loss 0.051858722413890064, precision_score 0.3880920748032288, recall_score 0.3718625614018101, f1_score 0.363703233700763
21-11-04 16:53:29, INFO: Test: loss 0.07503928795456886, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 16:57:56, INFO: ---------------------------------------Epoch 3---------------------------------------
21-11-04 16:57:56, INFO: Train: loss 0.05163988994900137, precision_score 0.397600561627201, recall_score 0.37627517407619226, f1_score 0.3694776927941065
21-11-04 16:57:56, INFO: Test: loss 0.07085910059511662, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:02:12, INFO: ---------------------------------------Epoch 4---------------------------------------
21-11-04 17:02:12, INFO: Train: loss 0.051464055525138976, precision_score 0.39437289201972353, recall_score 0.37341380667943286, f1_score 0.3672610877335998
21-11-04 17:02:12, INFO: Test: loss 0.0771069111675024, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:06:34, INFO: ---------------------------------------Epoch 5---------------------------------------
21-11-04 17:06:34, INFO: Train: loss 0.05152158131822944, precision_score 0.36915606865483586, recall_score 0.35721843381962176, f1_score 0.3481949514938891
21-11-04 17:06:34, INFO: Test: loss 0.07793437149375677, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:10:52, INFO: ---------------------------------------Epoch 6---------------------------------------
21-11-04 17:10:52, INFO: Train: loss 0.05098328528460115, precision_score 0.38617448111120484, recall_score 0.36814293531440573, f1_score 0.3623506829346846
21-11-04 17:10:52, INFO: Test: loss 0.08223239291459322, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:15:16, INFO: ---------------------------------------Epoch 7---------------------------------------
21-11-04 17:15:16, INFO: Train: loss 0.05132032470777631, precision_score 0.3893829690346084, recall_score 0.36812235833910684, f1_score 0.362319786986923
21-11-04 17:15:16, INFO: Test: loss 0.08004823807626962, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:19:20, INFO: ---------------------------------------Epoch 8---------------------------------------
21-11-04 17:19:20, INFO: Train: loss 0.05143840408418328, precision_score 0.38499909550324846, recall_score 0.3639098306904853, f1_score 0.3584288568288458
21-11-04 17:19:20, INFO: Test: loss 0.07708090690895915, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:23:43, INFO: ---------------------------------------Epoch 9---------------------------------------
21-11-04 17:23:43, INFO: Train: loss 0.05103822224773467, precision_score 0.3825803541495511, recall_score 0.3625972281385852, f1_score 0.3575419106198649
21-11-04 17:23:43, INFO: Test: loss 0.08260739795863628, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:27:58, INFO: ---------------------------------------Epoch 10---------------------------------------
21-11-04 17:27:58, INFO: Train: loss 0.050941459210589526, precision_score 0.3894387778483712, recall_score 0.3754916661705801, f1_score 0.36827880667321206
21-11-04 17:27:58, INFO: Test: loss 0.07571510056033731, precision_score 0.30888888888888894, recall_score 0.3243987127371274, f1_score 0.30930452745739373
21-11-04 17:28:00, INFO: --------------------------------------------------------------------------------------
21-11-04 17:28:00, INFO:                                        Result                                         
21-11-04 17:28:00, INFO: --------------------------------------------------------------------------------------
21-11-04 17:29:57, INFO: Train:
21-11-04 17:29:57, INFO: 
              precision    recall  f1-score   support

           B       0.12      0.27      0.17       712
           I       0.18      0.08      0.11       444
           O       0.84      0.73      0.78      5244

    accuracy                           0.64      6400
   macro avg       0.38      0.36      0.35      6400
weighted avg       0.71      0.64      0.67      6400

21-11-04 17:29:57, INFO: Test: 
21-11-04 17:29:57, INFO: 
              precision    recall  f1-score   support

           B       0.11      0.22      0.15       192
           I       0.00      0.00      0.00        96
           O       0.82      0.75      0.78      1312

    accuracy                           0.64      1600
   macro avg       0.31      0.32      0.31      1600
weighted avg       0.68      0.64      0.66      1600

